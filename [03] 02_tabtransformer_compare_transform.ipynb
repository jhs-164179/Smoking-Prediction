{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989c68e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7c4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c4e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./impute_set/imp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd42ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y, cat_col, numeric_col):\n",
    "        self.X_cat = np.array(x[cat_col]).astype(np.int32)\n",
    "        self.X_num = np.array(x[numeric_col]).astype(np.float32)\n",
    "        self.y = np.array(y).astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_cat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_cat = torch.from_numpy(self.X_cat[idx])\n",
    "        X_num = torch.from_numpy(self.X_num[idx])\n",
    "        y = torch.from_numpy(self.y[idx])\n",
    "        return X_cat, X_num, y\n",
    "    \n",
    "\n",
    "def preprocessing(df, numeric='minmax', category='label'):\n",
    "    X = df.drop('BS3_1', axis=1)\n",
    "    y = df[['BS3_1']]\n",
    "    numeric_col = [\n",
    "        'FEV1', 'FEV1FVC', 'age', 'BS6_3', 'BS6_2_1', 'BD1',\n",
    "        '건강문해력', 'Total_slp_wk', 'EQ_5D', 'BE3_31', 'BE5_1', '질환유병기간'\n",
    "    ]\n",
    "    cat_col = []\n",
    "    for col in X.columns:\n",
    "        if col not in numeric_col:\n",
    "            cat_col.append(col)\n",
    "\n",
    "    df_num, df_cat = X[numeric_col], X[cat_col]\n",
    "    if numeric == 'minmax':\n",
    "        n_pre = MinMaxScaler()\n",
    "    else:\n",
    "        n_pre = StandardScaler()\n",
    "    df_num = pd.DataFrame(n_pre.fit_transform(df_num), columns=df_num.columns)\n",
    "\n",
    "    if category == 'label':\n",
    "        c_pre = OrdinalEncoder()\n",
    "        df_cat = pd.DataFrame(c_pre.fit_transform(df_cat), columns=df_cat.columns)\n",
    "    else:\n",
    "        c_pre = OneHotEncoder(sparse_output=False)\n",
    "        df_cat = pd.DataFrame(c_pre.fit_transform(df_cat))\n",
    "\n",
    "    X = pd.concat([df_num, df_cat], axis=1)\n",
    "    uniques = []\n",
    "    for col in cat_col:\n",
    "        uniques.append(len(X[col].unique()))\n",
    "\n",
    "    return X, y, uniques, numeric_col, cat_col    \n",
    "\n",
    "\n",
    "def test_with_imputations(train_loader, test_loader, train_X, test_y, numeric_col, uniques):\n",
    "    combined_array = np.column_stack((train_X[numeric_col].mean().values, train_X[numeric_col].std().values))\n",
    "\n",
    "    # class_counts = torch.tensor([test_y.value_counts()[0], test_y.value_counts()[1]])\n",
    "    # class_weights = 1.0 / class_counts\n",
    "    # class_weights /= class_weights.sum()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_negatives = (test_y == 0).sum()\n",
    "    num_positives = (test_y == 1).sum()\n",
    "    class_weights = torch.tensor(num_negatives / num_positives, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "    print(f'Weights: {class_weights}')\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    model = TabTransformer(\n",
    "        categories=tuple(uniques),\n",
    "        num_continuous=len(numeric_col),\n",
    "        dim=64,dim_out=1,depth=6,heads=8,attn_dropout=.1,ff_dropout=.1,mlp_hidden_mults=(4,2),\n",
    "        mlp_act=nn.ReLU(inplace=True),\n",
    "        continuous_mean_std=torch.tensor(combined_array, dtype=torch.float32)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optim = Adam(model.parameters(), lr=.0001)\n",
    "    # criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "    best_f1 = 0.0\n",
    "    best_epoch = 0\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for x_cat, x_num, yy in train_loader:\n",
    "            optim.zero_grad()\n",
    "            x_cat, x_num, yy = x_cat.to(device), x_num.to(device), yy.to(device)\n",
    "            preds = model(x_cat, x_num)\n",
    "            loss = criterion(preds.squeeze(), yy.squeeze())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item()\n",
    "        # print(f'{epoch+1} Epoch | Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for x_cat, x_num, yy in test_loader:\n",
    "                x_cat, x_num, yy = x_cat.to(device), x_num.to(device), yy.to(device)\n",
    "                preds = model(x_cat, x_num)\n",
    "                val_loss += criterion(preds.squeeze(), yy.squeeze()).item()\n",
    "                yy = yy.detach().cpu().numpy().squeeze()\n",
    "                preds = torch.sigmoid(preds).detach().cpu().numpy().squeeze()\n",
    "                pred_labels = np.where(preds>=.5, 1, 0)\n",
    "                correct += (pred_labels == yy).sum().item()\n",
    "                \n",
    "                val_preds.extend(pred_labels.tolist())\n",
    "                val_targets.extend(yy.tolist())\n",
    "        val_loss /= len(test_loader)\n",
    "        val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_epoch = epoch+1\n",
    "            torch.save(model.state_dict(), 'bestTabTransformer.pth')\n",
    "            \n",
    "    print(f'Best Epoch: {best_epoch} | Best F1 : {best_f1:.4f}')  \n",
    "    return best_f1  \n",
    "\n",
    "\n",
    "def test_with_5fold(df, numeric, category, shuffle=True):\n",
    "    f1s = []\n",
    "    X, y, uniques, numeric_col, cat_col = preprocessing(df, numeric, category)\n",
    "    if shuffle:\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=shuffle, random_state=42)\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=shuffle)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        train_X, train_y = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        test_X, test_y = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_set = CustomDataset(train_X, train_y, cat_col, numeric_col)\n",
    "        test_set = CustomDataset(test_X, test_y, cat_col, numeric_col)\n",
    "        train_loader = DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=True)\n",
    "        test_loader = DataLoader(test_set, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "        f1_value = test_with_imputations(\n",
    "            train_loader, test_loader, train_X, test_y, numeric_col, uniques\n",
    "        )\n",
    "        f1s.append(f1_value)\n",
    "\n",
    "    return f1s\n",
    "\n",
    "\n",
    "def get_cv_results(f1s:list):\n",
    "    f1s = np.array(f1s)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    std_f1 = np.std(f1s)\n",
    "    ci95 = st.t.interval(.95, df=len(f1s)-1, loc=mean_f1, scale=std_f1/np.sqrt(len(f1s)))\n",
    "    return mean_f1, std_f1, ci95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f2db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 2 | Best F1 : 0.8250\n",
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 7 | Best F1 : 0.7883\n",
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 1 | Best F1 : 0.7321\n",
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 3 | Best F1 : 0.6764\n",
      "Weights: tensor([5.3636], device='cuda:0')\n",
      "Best Epoch: 3 | Best F1 : 0.7809\n",
      "[0.825, 0.7883064516129032, 0.7321428571428572, 0.6764252696456087, 0.7808695652173914]\n",
      "CV Results: Mean 0.76 | Std 0.05 | CI95% 0.70~0.82\n"
     ]
    }
   ],
   "source": [
    "# minmax | label\n",
    "f1s = test_with_5fold(df, numeric='minmax', category='label')\n",
    "mean_f1, std_f1, ci95 = get_cv_results(f1s)\n",
    "print(f1s)\n",
    "print(f'CV Results: Mean {mean_f1:.2f} | Std {std_f1:.2f} | CI95% {ci95[0]:.2f}~{ci95[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191e66c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 3 | Best F1 : 0.8179\n",
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 9 | Best F1 : 0.7659\n",
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 7 | Best F1 : 0.7486\n",
      "Weights: tensor([6.], device='cuda:0')\n",
      "Best Epoch: 2 | Best F1 : 0.6812\n",
      "Weights: tensor([5.3636], device='cuda:0')\n",
      "Best Epoch: 3 | Best F1 : 0.7989\n",
      "[0.8179115570419918, 0.765886287625418, 0.7485632183908046, 0.6812386156648452, 0.7988505747126436]\n",
      "CV Results: Mean 0.76 | Std 0.05 | CI95% 0.70~0.82\n"
     ]
    }
   ],
   "source": [
    "# standard | label\n",
    "f1s = test_with_5fold(df, numeric='standard', category='label')\n",
    "mean_f1, std_f1, ci95 = get_cv_results(f1s)\n",
    "print(f1s)\n",
    "print(f'CV Results: Mean {mean_f1:.2f} | Std {std_f1:.2f} | CI95% {ci95[0]:.2f}~{ci95[1]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhs_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
